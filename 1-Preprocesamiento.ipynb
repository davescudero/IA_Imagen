{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de Neumonias con Deep Learning\n",
    "\n",
    "Entrenaremos un clasificador para predecir si una radiografía de un paciente muestra signos de neumonía o no, basado en el [Desafío de Detección de Neumonía de la RSNA](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge)\n",
    "\n",
    "## Obtención de Datos\n",
    "\n",
    "En el artículo de Wang et al. [@Wang2017], se presenta la base de datos ChestX-ray8, que incluye benchmarks para la clasificación y localización de enfermedades torácicas comunes.\n",
    "\n",
    "Primero, descargamos los datos de [Kaggle](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data)\n",
    "\n",
    "Fuente Original: https://nihcc.app.box.com/v/ChestXray-NIHCC\n",
    "\n",
    "1. **Escala del Dataset:**\n",
    "- El **ChestX-ray8** es una base de datos masiva que contiene **108,948 imágenes de rayos X** en vista frontal de **32,717 pacientes únicos**. Estas imágenes fueron recolectadas de sistemas de archivado y comunicación de imágenes (PACS) de un hospital, y abarcan un período desde **1992 hasta 2015**.\n",
    "- Cada imagen está etiquetada con una o múltiples de **ocho enfermedades comunes del tórax** (Atelectasia, Cardiomegalia, Derrame, Infiltración, Masa, Nódulo, Neumonía y Neumotórax).\n",
    "\n",
    "2. **Etiquetado mediante Procesamiento de Lenguaje Natural (NLP):**\n",
    "- Las etiquetas de las enfermedades se extrajeron automáticamente de los informes radiológicos asociados a cada imagen usando técnicas de NLP. Esto permitió generar etiquetas débilmente supervisadas, es decir, etiquetas a nivel de imagen sin la necesidad de anotación manual exhaustiva, lo que sería impracticable a esta escala.\n",
    "- Herramientas de NLP como **DNorm** y **MetaMap** fueron usadas para identificar y normalizar los conceptos de enfermedades a partir de los informes. También se desarrollaron reglas personalizadas para manejar la **negación** e **incertidumbre** en las anotaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "Este notebook realiza varias tareas críticas de preprocesamiento, este se refiere a una serie de pasos realizados para transformar las imágenes de rayos X originales y las etiquetas asociadas a un formato que pueda ser utilizado de manera eficiente por un modelo de aprendizaje profundo. Estos pasos son fundamentales porque los datos *crudos*, tal como están, no siempre son ideales para ser introducidos directamente en un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las variables del archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la ruta del archivo\n",
    "data_path = os.getenv('DATA_PATH')\n",
    "print(f\"Ruta cargada: {data_path}\") \n",
    "\n",
    "\n",
    "data_path = os.getenv('DATA_PATH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(data_path)\n",
    "labels.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el archivo CSV que contiene las etiquetas asociadas a las imágenes. Cada fila contiene un patientId, coordenadas para posibles consolidaciomes (si se detecta neumonía), y la variable `Target`, que indica si la imagen tiene o no signos de neumonía.\n",
    "\n",
    "El Target es binario (1 = neumonía, 0 = no neumonía). Esta es la variable objetivo que el modelo aprenderá a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover entradas duplicadas\n",
    "labels = labels.drop_duplicates(\"patientId\")\n",
    "labels.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan duplicados en las filas que contienen el mismo `patientId`. Esto es importante porque tener múltiples entradas para el mismo paciente podría causar problemas en el entrenamiento del modelo, como sesgo o sobreajuste.\n",
    "\n",
    "Cada paciente debe ser representado una única vez en el análisis, para evitar una ponderación excesiva de imágenes de un mismo paciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Target'].value_counts().plot(kind='bar', title='Distribución de etiquetas de neumonía')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la distribución de las etiquetas para identificar cualquier desbalance en los datos. Un fuerte desbalance, como un número desproporcionado de imágenes sin neumonía, puede afectar el desempeño del modelo y requerir estrategias como submuestreo o sobrepeso en la clase minoritaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "ROOT_PATH = Path(os.getenv('IMAGE_PATH'))\n",
    "SAVE_PATH = Path(\"Processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(3, 3, figsize=(9, 9))\n",
    "c = 0\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        patient_id = labels.patientId.iloc[c]\n",
    "        dcm_path = ROOT_PATH/patient_id\n",
    "        dcm_path = dcm_path.with_suffix(\".dcm\")\n",
    "        dcm = pydicom.read_file(dcm_path).pixel_array\n",
    "        \n",
    "        label = labels[\"Target\"].iloc[c]\n",
    "        \n",
    "        axis[i][j].imshow(dcm, cmap=\"bone\")\n",
    "        axis[i][j].set_title(label)\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos si la calidad de las imágenes es adecuada para el entrenamiento de un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos\n",
    "\n",
    "Para manejar eficientemente nuestros datos, convertimos las imágenes de rayos X almacenadas en formato DICOM a matrices.\n",
    "\n",
    "Posteriormente, calculamos la media y la desviación estándar general de los píxeles de todo el conjunto de datos con el propósito de normalización.\n",
    "\n",
    "Luego, las imágenes en matrices creadas se almacenan en dos carpetas separadas según su etiqueta binaria:\n",
    "- $0$: Todas las radiografías que no muestran signos de neumonía\n",
    "- $1$: Todas las radiografías que muestran signos de neumonía\n",
    "\n",
    "Estandarizamos todas las imágenes utilizando el valor máximo de píxel en el conjunto de datos proporcionado, 255. Todas las imágenes se redimensionan a 224x224.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = 0  # Inicializa la variable para acumular la suma de los píxeles\n",
    "sums_squared = 0  # Inicializa la variable para acumular la suma de los cuadrados de los píxeles\n",
    "\n",
    "# Itera sobre el DataFrame de etiquetas, obteniendo el índice (c) y el ID del paciente (patient_id)\n",
    "for c, patient_id in enumerate(tqdm(labels.patientId)):  \n",
    "    # Crea la ruta completa al archivo DICOM correspondiente al paciente\n",
    "    dcm_path = ROOT_PATH/patient_id  \n",
    "    dcm_path = dcm_path.with_suffix(\".dcm\")  # Añade la extensión \".dcm\" al archivo para que sea legible como DICOM\n",
    "    \n",
    "    # Lee el archivo DICOM usando pydicom y normaliza los valores de los píxeles dividiendo entre 255\n",
    "    dcm = pydicom.read_file(dcm_path).pixel_array / 255  \n",
    "    \n",
    "    # Redimensiona la imagen, ya que 1024x1024 es demasiado grande para manejar en modelos de Deep Learning.\n",
    "    # Cambiamos a una resolución de 224x224.\n",
    "    # Convertimos la imagen a tipo float16 para usar menos memoria al almacenar la imagen.\n",
    "    dcm_array = cv2.resize(dcm, (224, 224)).astype(np.float16)\n",
    "    \n",
    "    # Recupera la etiqueta correspondiente a la imagen del paciente (0 para sano, 1 para neumonía)\n",
    "    label = labels.Target.iloc[c]\n",
    "    \n",
    "    # Divide el conjunto de datos en 4/5 para entrenamiento y 1/5 para validación\n",
    "    train_or_val = \"train\" if c < 24000 else \"val\"  \n",
    "    \n",
    "    # Define la ruta de guardado y crea las carpetas necesarias si no existen\n",
    "    current_save_path = SAVE_PATH/train_or_val/str(label)  \n",
    "    current_save_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Guarda el array de la imagen en el directorio correspondiente (train/val y clase 0 o 1)\n",
    "    np.save(current_save_path/patient_id, dcm_array)  \n",
    "    \n",
    "    # Normaliza la suma de los píxeles dividiendo por el número total de píxeles en la imagen (224x224)\n",
    "    normalizer = dcm_array.shape[0] * dcm_array.shape[1]  \n",
    "    \n",
    "    # Solo calcula estadísticas de las imágenes de entrenamiento (no para validación)\n",
    "    if train_or_val == \"train\":  \n",
    "        # Suma los valores de los píxeles normalizados de cada imagen para calcular la media posteriormente\n",
    "        sums += np.sum(dcm_array) / normalizer  \n",
    "        \n",
    "        # Suma los cuadrados de los píxeles normalizados de cada imagen para calcular la desviación estándar posteriormente\n",
    "        sums_squared += (np.power(dcm_array, 2).sum()) / normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcular Media y Desviación Estándar del Dataset\n",
    "\n",
    "Para calcular la media y la desviación estándar del conjunto de datos, calculamos la suma de los valores de los píxeles, así como la suma de los valores de píxeles al cuadrado para cada sujeto. Esto permite calcular la media y la desviación estándar general sin mantener todo el conjunto de datos en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = sums / 24000\n",
    "std = np.sqrt(sums_squared / 24000 - (mean**2))\n",
    "\n",
    "print(f\"Mean of Dataset: {mean}, STD: {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Media**\n",
    "\n",
    "$\\mu = \\frac{\\text{sums}}{24000}$\n",
    "\n",
    "Donde `sums` es la suma acumulada de los valores de píxeles de todas las imágenes de entrenamiento, y `24000` es el número total de imágenes en el conjunto de entrenamiento.\n",
    "\n",
    "**Desviación Estándar**\n",
    "$\\sigma = \\sqrt{\\frac{\\text{sums squared}}{24000} - \\mu^2}$\n",
    "\n",
    "Donde:\n",
    "- `sums squared` es la suma acumulada de los cuadrados de los valores de los píxeles.\n",
    "- `mean**2` es el cuadrado de la media que ya se ha calculado.\n",
    "\n",
    "\n",
    "La normalización es importante para asegurarse de que los valores de los píxeles estén en un rango que permita a las redes neuronales converger más rápido y con mayor precisión. Al normalizar, centramos los valores en torno a la media (0.49) y escalamos con la desviación estándar.\n",
    "\n",
    "Este paso asegura que las variaciones en brillo o contraste no afecten el rendimiento del modelo de manera injustificada, permitiendo que la red neuronal se concentre en las características importantes para el diagnóstico, como las consolidaciones pulmonares."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

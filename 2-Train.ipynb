{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strange-psychiatry",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "En este notebook crearemos y entrenaremos un clasificador en el conjunto de datos de radiografías de tórax para clasificar si una imagen muestra signos de neumonía o no."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-timothy",
   "metadata": {},
   "source": [
    "\n",
    "**Importaciones**:\n",
    "\n",
    "* `torch` y `torchvision` para la creación del modelo y los dataloaders.\n",
    "* `transforms` de `torchvision` para la Augmentación de Datos y Normalización.\n",
    "* `torchmetrics` para una fácil computación de métricas.\n",
    "* `pytorch_lightning` para una implementación de entrenamiento eficiente y sencilla.\n",
    "* `ModelCheckpoint` y `TensorBoardLogger` para guardar puntos de control (checkpoints) y registro de datos.\n",
    "* `tqdm` para la barra de progreso al validar el modelo.\n",
    "* `numpy` para todo tipo de operaciones :)\n",
    "* `matplotlib` para visualizar algunas imágenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dressed-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-official",
   "metadata": {},
   "source": [
    "Primero, creamos nuestro conjunto de datos. Podemos aprovechar **DatasetFolder** de `torchvision`: nos permite simplemente pasar un directorio raíz y devolver un objeto de conjunto de datos con acceso a todos los archivos dentro del directorio, utilizando el nombre del directorio como etiqueta de clase. <br />\n",
    "Solo necesitamos definir una función de carga, **load_file**, que especifique cómo se deben cargar los archivos. Esto es muy cómodo, ya que solo tenemos que cargar nuestros archivos previamente almacenados en formato numpy. \n",
    "\n",
    "Además, necesitamos definir una lista de extensiones de archivo (en nuestro caso, solo \"npy\").\n",
    "\n",
    "Finalmente, podemos pasar una secuencia de transformaciones para la Augmentación de Datos y Normalización.\n",
    "\n",
    "Usamos:\n",
    "* **RandomResizedCrops**, que aplica un recorte aleatorio de la imagen y la redimensiona al tamaño original de la imagen (224x224).\n",
    "* **Rotaciones aleatorias** entre -5 y 5 grados.\n",
    "* **Traslación aleatoria** (máximo 5%).\n",
    "* **Escalado aleatorio** (0.9-1.1 del tamaño original de la imagen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "explicit-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convierte el arreglo numpy a tensor\n",
    "    transforms.Normalize(0.49, 0.248),  # Normaliza usando la media y desviación estándar del notebook de preprocesamiento\n",
    "    transforms.RandomAffine(  # Data Augmentation\n",
    "        degrees=(-5, 5),  # Aplica rotaciones aleatorias entre -5 y 5 grados\n",
    "        translate=(0, 0.05),  # Aplica traslación aleatoria con un máximo del 5%\n",
    "        scale=(0.9, 1.1)  # Escala aleatoriamente la imagen entre 90% y 110% de su tamaño original\n",
    "    ),\n",
    "    transforms.RandomResizedCrop((224, 224), scale=(0.35, 1))  # Aplica un recorte aleatorio y redimensiona a 224x224 píxeles\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convierte el arreglo numpy a tensor\n",
    "    transforms.Normalize([0.49], [0.248])  # Normaliza usando la media y desviación estándar del notebook de preprocesamiento\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-bread",
   "metadata": {},
   "source": [
    "Finalmente, creamos el conjunto de datos de entrenamiento y validación, junto con los respectivos cargadores de datos (data loaders).\n",
    "\n",
    "Por favor, adapta el tamaño del lote (batch size) y el número de trabajadores (num_workers) de acuerdo con los recursos de tu hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basic-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from torchvision import datasets\n",
    "from utils import load_file\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener las rutas de los conjuntos de datos (datasets) desde las variables de entorno\n",
    "train_dataset_path = os.getenv('TRAIN_DATASET_PATH')\n",
    "val_dataset_path = os.getenv('VAL_DATASET_PATH')\n",
    "\n",
    "# Asegurarse de que las rutas se hayan cargado correctamente desde el archivo .env\n",
    "if train_dataset_path is None or val_dataset_path is None:\n",
    "    raise ValueError(\"Las rutas de los datasets no están definidas en el archivo .env.\")\n",
    "\n",
    "# Crear el conjunto de datos de entrenamiento usando la ruta obtenida y la función de carga\n",
    "train_dataset = datasets.DatasetFolder(\n",
    "    train_dataset_path,  # Ruta al directorio de los datos de entrenamiento\n",
    "    loader=load_file,  # Función personalizada para cargar los archivos\n",
    "    extensions=\"npy\",  # Especificar las extensiones de archivo a cargar (en este caso, archivos .npy)\n",
    "    transform=train_transforms  # Aplicar las transformaciones definidas para los datos de entrenamiento\n",
    ")\n",
    "\n",
    "# Crear el conjunto de datos de validación usando la ruta obtenida y la función de carga\n",
    "val_dataset = datasets.DatasetFolder(\n",
    "    val_dataset_path,  # Ruta al directorio de los datos de validación\n",
    "    loader=load_file,  # Función personalizada para cargar los archivos\n",
    "    extensions=\"npy\",  # Especificar las extensiones de archivo a cargar (en este caso, archivos .npy)\n",
    "    transform=val_transforms  # Aplicar las transformaciones definidas para los datos de validación\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-numbers",
   "metadata": {},
   "source": [
    "### Imagenes despues del Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionemos algunas imágenes aumentadas del conjunto de entrenamiento\n",
    "fig, axis = plt.subplots(2, 2, figsize=(9, 9))  # Crear una cuadrícula de 2x2 para mostrar las imágenes, con un tamaño de figura de 9x9 pulgadas\n",
    "\n",
    "for i in range(2):  # Iterar sobre las filas de la cuadrícula\n",
    "    for j in range(2):  # Iterar sobre las columnas de la cuadrícula\n",
    "        random_index = np.random.randint(0, 20000)  # Obtener un índice aleatorio entre 0 y 20000 para seleccionar una imagen del conjunto de datos de entrenamiento\n",
    "        x_ray, label = train_dataset[random_index]  # Obtener la imagen y la etiqueta correspondientes al índice aleatorio\n",
    "        axis[i][j].imshow(x_ray[0], cmap=\"bone\")  # Mostrar la imagen en escala de grises (\"bone\" es un mapa de colores adecuado para rayos X)\n",
    "        axis[i][j].set_title(f\"Label: {label}\")  # Establecer el título de la imagen, mostrando su etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Tamaño del lote (batch size), es decir, el número de muestras que se procesarán juntas en cada iteración\n",
    "num_workers = 4  # Número de trabajadores (workers) para cargar los datos en paralelo, lo que puede acelerar el proceso\n",
    "\n",
    "# Crear el DataLoader para el conjunto de entrenamiento\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,  # El conjunto de datos de entrenamiento\n",
    "    batch_size=batch_size,  # Número de muestras por lote\n",
    "    num_workers=num_workers,  # Número de procesos en paralelo para cargar los datos\n",
    "    shuffle=True,  # Barajar los datos en cada época para mejorar la generalización\n",
    "    persistent_workers=True  # Mantener los procesos de los trabajadores activos entre épocas para una carga más eficiente\n",
    ")\n",
    "\n",
    "# Crear el DataLoader para el conjunto de validación\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,  # El conjunto de datos de validación\n",
    "    batch_size=batch_size,  # Número de muestras por lote\n",
    "    num_workers=num_workers,  # Número de procesos en paralelo para cargar los datos\n",
    "    shuffle=False,  # No barajar los datos de validación, ya que no es necesario\n",
    "    persistent_workers=True  # Mantener los procesos de los trabajadores activos entre épocas\n",
    ")\n",
    "\n",
    "# Imprimir el número de imágenes en los conjuntos de entrenamiento y validación\n",
    "print(f\"Tenemos {len(train_dataset)} imágenes de entrenamiento y {len(val_dataset)} imágenes de validación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-poetry",
   "metadata": {},
   "source": [
    "Las clases están desequilibradas: hay más imágenes sin signos de neumonía que con neumonía.\n",
    "Existen múltiples maneras de manejar conjuntos de datos desequilibrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los valores únicos y sus respectivas cantidades en las etiquetas del conjunto de entrenamiento y validación\n",
    "# np.unique devuelve los valores únicos en un arreglo y return_counts=True hace que también devuelva la cantidad de veces que aparece cada valor\n",
    "np.unique(train_dataset.targets, return_counts=True), np.unique(val_dataset.targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-vinyl",
   "metadata": {},
   "source": [
    "## Creación del Modelo \n",
    "\n",
    "Cada modelo en PyTorch Lightning se define al menos por un método de inicialización, una función **forward** que define el paso hacia adelante/predicción, un **training_step** que calcula la pérdida y **configure_optimizers** para especificar el algoritmo de optimización.\n",
    "\n",
    "Además, podemos usar un callback **training_epoch_end** para calcular estadísticas y métricas generales del conjunto de datos, como la precisión.\n",
    "\n",
    "Posteriormente, definimos el **validation_step**. El paso de validación realiza prácticamente los mismos pasos que el paso de entrenamiento, pero en los datos de validación. En este caso, PyTorch Lightning no actualiza los pesos. Nuevamente, podemos usar **validation_epoch_end** para calcular las métricas generales del conjunto de datos.\n",
    "\n",
    "No se necesitan bucles ni actualizaciones manuales de los pesos\n",
    "\n",
    "Además, PyTorch Lightning también maneja la gestión de dispositivos. Solo es necesario pasar el número de GPUs al crear el entrenador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-demonstration",
   "metadata": {},
   "source": [
    "Usaremos la arquitectura de la red ResNet18.\n",
    "\n",
    "Como la mayoría de los modelos de `torchvision`, la ResNet original espera una entrada de tres canales en **conv1**.  \n",
    "Sin embargo, nuestros datos de imágenes de rayos X tienen solo un canal.  \n",
    "Por lo tanto, necesitamos cambiar el parámetro `in_channel` de 3 a 1.\n",
    "\n",
    "Además, cambiaremos la última capa totalmente conectada para que tenga solo una salida, ya que tenemos una etiqueta de clase binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-communication",
   "metadata": {},
   "source": [
    "### Optimizador y Función de Pérdida\n",
    "\n",
    "Usamos el optimizador **Adam** con una tasa de aprendizaje de 0.0001 y la función de pérdida **BinaryCrossEntropy**.  \n",
    "(De hecho, usamos **BCEWithLogitsLoss**, que acepta directamente los valores predichos sin procesar y calcula la función de activación sigmoide antes de aplicar la Entropía Cruzada).\n",
    "\n",
    "Si lo deseas, puedes asignar un peso diferente de 1 al modelo de neumonía para utilizar la función de pérdida ponderada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opening-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la clase del modelo de neumonía usando PyTorch Lightning\n",
    "class PneumoniaModel(pl.LightningModule):\n",
    "    def __init__(self, weight=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Crear el modelo base usando ResNet18 de torchvision\n",
    "        self.model = torchvision.models.resnet18()\n",
    "        \n",
    "        # Cambiar conv1 de 3 a 1 canal de entrada, ya que nuestras imágenes de rayos X son en escala de grises\n",
    "        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # Cambiar la última capa totalmente conectada (llamada 'fc' en ResNet18) para que tenga una salida (clase binaria)\n",
    "        self.model.fc = torch.nn.Linear(in_features=512, out_features=1)\n",
    "        \n",
    "        # Definir el optimizador Adam con una tasa de aprendizaje de 1e-4\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        \n",
    "        # Definir la función de pérdida con BCEWithLogitsLoss y agregar peso para las clases positivas\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([weight]))\n",
    "        \n",
    "        # Calcular la precisión (accuracy) de manera sencilla para entrenamiento y validación\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"binary\")\n",
    "\n",
    "        # Almacenamiento para las salidas de las etapas de entrenamiento y validación\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    # Definir el paso hacia adelante (predicción)\n",
    "    def forward(self, data):\n",
    "        pred = self.model(data)\n",
    "        return pred\n",
    "    \n",
    "    # Definir el paso de entrenamiento\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_ray, label = batch\n",
    "        label = label.float()  # Convertir la etiqueta a float (necesario para la función de pérdida)\n",
    "        pred = self(x_ray)[:, 0]  # Predicción: asegurar que la predicción y la etiqueta tengan la misma forma\n",
    "        loss = self.loss_fn(pred, label)  # Calcular la pérdida\n",
    "        \n",
    "        # Registrar la pérdida y la precisión por lote\n",
    "        self.log(\"Train Loss\", loss)\n",
    "        self.log(\"Step Train Acc\", self.train_acc(torch.sigmoid(pred), label.int()))\n",
    "\n",
    "        # Guardar la salida para su uso posterior al final de la época\n",
    "        self.training_step_outputs.append({\"loss\": loss})\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Operación al final de una época de entrenamiento\n",
    "    def on_train_epoch_end(self):\n",
    "        # Después de una época, calcular la precisión de todo el conjunto de datos de entrenamiento\n",
    "        self.log(\"Train Acc\", self.train_acc.compute())\n",
    "        # Limpiar las salidas almacenadas\n",
    "        self.training_step_outputs.clear()\n",
    "        \n",
    "    # Definir el paso de validación\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Mismos pasos que en el training_step\n",
    "        x_ray, label = batch\n",
    "        label = label.float()\n",
    "        pred = self(x_ray)[:, 0]  # Asegurarse de que la predicción y la etiqueta tengan la misma forma\n",
    "\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        # Registrar las métricas de validación\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"Step Val Acc\", self.val_acc(torch.sigmoid(pred), label.int()))\n",
    "\n",
    "        # Guardar la salida para su uso posterior al final de la época\n",
    "        self.validation_step_outputs.append({\"loss\": loss})\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    # Operación al final de una época de validación\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Después de una época, calcular la precisión de todo el conjunto de datos de validación\n",
    "        self.log(\"Val Acc\", self.val_acc.compute())\n",
    "        # Limpiar las salidas almacenadas\n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    # Configurar los optimizadores\n",
    "    def configure_optimizers(self):\n",
    "        # Siempre retornar una lista de optimizadores\n",
    "        return [self.optimizer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "armed-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PneumoniaModel()  # Incia el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-death",
   "metadata": {},
   "source": [
    "Creamos un callback para puntos de control (checkpoint) que solo guarda los 10 mejores modelos basándose en la precisión de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "formal-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el callback para el punto de control\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='Val Acc',  # Monitorizar la métrica de precisión en la validación ('Val Acc')\n",
    "    save_top_k=10,  # Guardar solo los 10 mejores modelos\n",
    "    mode='max'  # Guardar los modelos que maximicen la métrica ('Val Acc')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-commodity",
   "metadata": {},
   "source": [
    "Trainer documentation: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define el número de dispositivos (GPUs o CPUs) a utilizar\n",
    "devices = 1  # Cambia a 0 para usar solo la CPU, o usa una lista como [0, 1] para utilizar múltiples GPUs\n",
    "\n",
    "# Define el callback para guardar puntos de control (checkpoints)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",  # Monitorizar la métrica de pérdida en validación (\"val_loss\")\n",
    "    dirpath=\"./checkpoints\",  # Directorio donde se guardarán los checkpoints\n",
    "    filename=\"best-checkpoint\",  # Nombre base para el archivo de checkpoint\n",
    "    save_top_k=1,  # Guardar solo el mejor modelo (1) según la métrica monitorizada\n",
    "    mode=\"min\"  # Guardar el modelo que minimice la métrica (\"val_loss\")\n",
    ")\n",
    "\n",
    "# Configura el logger para TensorBoard\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"./logs\",  # Directorio donde se guardarán los registros de TensorBoard\n",
    "    name=\"my_model\"  # Nombre de la carpeta del modelo en los registros\n",
    ")\n",
    "\n",
    "# Crea el trainer con los parámetros especificados\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\" if devices > 0 else \"cpu\",  # Usar \"gpu\" si devices > 0, de lo contrario \"cpu\"\n",
    "    devices=devices,  # Especifica cuántos dispositivos (GPUs o CPUs) usar\n",
    "    logger=logger,  # Asigna el logger configurado previamente\n",
    "    log_every_n_steps=1,  # Registrar información en TensorBoard en cada paso\n",
    "    callbacks=[checkpoint_callback],  # Añadir el callback de checkpoint al trainer\n",
    "    max_epochs=35  # Número máximo de épocas de entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia el proceso de entrenamiento del modelo\n",
    "trainer.fit(\n",
    "    model,        # El modelo a entrenar (debe ser una instancia de PneumoniaModel u otro modelo de PyTorch Lightning)\n",
    "    train_loader, # DataLoader para el conjunto de datos de entrenamiento\n",
    "    val_loader    # DataLoader para el conjunto de datos de validación\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-accreditation",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "Primero, cargamos el último punto de control y enviamos el modelo a la GPU, si es posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-federation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Establecer el dispositivo a utilizar: GPU (\"cuda:0\") si está disponible, de lo contrario, usar la CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar el modelo desde el checkpoint. Usar strict=False para evitar coincidencia exacta de algunos parámetros (como pos_weight)\n",
    "model = PneumoniaModel.load_from_checkpoint(\"weights/weights_1.ckpt\")\n",
    "model.eval()  # Configurar el modelo en modo de evaluación (desactiva dropout, batch normalization, etc.)\n",
    "model.to(device)  # Enviar el modelo al dispositivo seleccionado (GPU o CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-comparative",
   "metadata": {},
   "source": [
    "Calcular las predicciones en todo el conjunto de datos de validación y almacenar las predicciones y las etiquetas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las predicciones en todo el conjunto de datos de validación y almacenar las predicciones y las etiquetas\n",
    "preds = []  # Lista para almacenar las predicciones\n",
    "labels = []  # Lista para almacenar las etiquetas verdaderas\n",
    "\n",
    "# Desactivar el cálculo del gradiente, ya que no es necesario durante la evaluación\n",
    "with torch.no_grad():\n",
    "    for data, label in tqdm(val_dataset):  # Iterar sobre todo el conjunto de datos de validación\n",
    "        data = data.to(device).float().unsqueeze(0)  # Enviar los datos al dispositivo (GPU/CPU) y añadir una dimensión extra para el lote\n",
    "        pred = torch.sigmoid(model(data)[0].cpu())  # Hacer la predicción, aplicar la función sigmoide y llevar la predicción a la CPU\n",
    "        preds.append(pred)  # Almacenar la predicción\n",
    "        labels.append(label)  # Almacenar la etiqueta verdadera\n",
    "\n",
    "# Convertir las listas de predicciones y etiquetas a tensores\n",
    "preds = torch.tensor(preds)\n",
    "labels = torch.tensor(labels).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-interstate",
   "metadata": {},
   "source": [
    "Calcular métricas:  \n",
    "Podemos ver que el resultado general ya es decente con nuestro modelo simple.  \n",
    "Sin embargo, sufrimos de una gran cantidad de falsos negativos debido al desequilibrio de los datos.  \n",
    "\n",
    "Intenta probar qué sucede si aumentas o disminuyes el peso en la función de pérdida.\n",
    "\n",
    "Una alternativa a volver a entrenar con una pérdida ponderada es reducir el umbral de clasificación de 0.5 a, por ejemplo, 0.25. Esto produce muchos menos falsos negativos, pero aumenta el número de falsos positivos.  \n",
    "Esto se llama el compromiso entre precisión y sensibilidad (*precision-recall tradeoff*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo que estás trabajando en un problema de clasificación binaria\n",
    "acc = torchmetrics.Accuracy(task=\"binary\")(preds, labels)\n",
    "precision = torchmetrics.Precision(task=\"binary\")(preds, labels)\n",
    "recall = torchmetrics.Recall(task=\"binary\")(preds, labels)\n",
    "\n",
    "# Ajuste en la ConfusionMatrix\n",
    "cm = torchmetrics.ConfusionMatrix(task=\"binary\")(preds, labels)\n",
    "cm_threshed = torchmetrics.ConfusionMatrix(task=\"binary\", threshold=0.25)(preds, labels)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Val Accuracy: {acc}\")\n",
    "print(f\"Val Precision: {precision}\")\n",
    "print(f\"Val Recall: {recall}\")\n",
    "print(f\"Confusion Matrix:\\n {cm}\")\n",
    "print(f\"Confusion Matrix (Threshold=0.25):\\n {cm_threshed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76449db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = torchmetrics.Accuracy(task=\"binary\")(preds, labels)\n",
    "precision = torchmetrics.Precision(task=\"binary\")(preds, labels)\n",
    "recall = torchmetrics.Recall(task=\"binary\")(preds, labels)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = torchmetrics.ConfusionMatrix(task=\"binary\")(preds, labels)\n",
    "cm_threshed = torchmetrics.ConfusionMatrix(task=\"binary\", threshold=0.25)(preds, labels)\n",
    "\n",
    "# Convertir la matriz de confusión a un formato NumPy para su visualización\n",
    "cm_np = cm.cpu().numpy()\n",
    "cm_threshed_np = cm_threshed.cpu().numpy()\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(cm_np, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax[0])\n",
    "ax[0].set_title(\"Confusion Matrix\")\n",
    "ax[0].set_xlabel(\"Predicted labels\")\n",
    "ax[0].set_ylabel(\"True labels\")\n",
    "\n",
    "sns.heatmap(cm_threshed_np, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax[1])\n",
    "ax[1].set_title(\"Confusion Matrix with Threshold=0.25\")\n",
    "ax[1].set_xlabel(\"Predicted labels\")\n",
    "ax[1].set_ylabel(\"True labels\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        rnd_idx = np.random.randint(0, len(preds))\n",
    "        axis[i][j].imshow(val_dataset[rnd_idx][0][0], cmap=\"bone\")\n",
    "        axis[i][j].set_title(f\"Pred:{int(preds[rnd_idx] > 0.5)}, Label:{labels[rnd_idx]}\")\n",
    "        axis[i][j].axis(\"off\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
